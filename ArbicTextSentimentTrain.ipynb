{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArbicTextSentimentTrain.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Library import and data exploration\n"
      ],
      "metadata": {
        "id": "IFs6PcvTpZyf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "wweNdbP4nuNL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
        "import joblib\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ocsSwwoDbvls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel(\"/content/AJGT.xlsx\")\n",
        "print(data.head())\n",
        "print(data.sample(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMdN1VUAZuTo",
        "outputId": "42bd9b39-81a3-48d1-acf8-8848a0dbe187"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID                                               Feed Sentiment\n",
            "0   1   اربد فيها جامعات اكثر من عمان ... وفيها قد عم...  Positive\n",
            "1   2   الحلو انكم بتحكوا على اساس انو الاردن ما فيه ...  Negative\n",
            "2   3                            كله رائع بجد ربنا يكرمك  Positive\n",
            "3   4                                 لسانك قذر يا قمامه  Negative\n",
            "4   5  ​انا داشره وغير متزوجه ولدي علاقات مشبوه واحشش...  Negative\n",
            "        ID                                               Feed Sentiment\n",
            "1126  1127  كان نفسي اكون شخص بارد ، يتقبل اي حاجه من غير ...  Negative\n",
            "1238  1239                             لازم يحكم عليهم بالسجن  Negative\n",
            "1317  1318           ما اضيق العيش لولا فسحه الامل  الحمد لله  Positive\n",
            "450    451       المهم الدعاء في السجود حتى تغسل عينيك الدموع  Positive\n",
            "445    446         المشكله ناس بتسمع حالها بالحمام هيه وبتغني  Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQK8CN9zsxu5",
        "outputId": "f79a2b72-927c-45d2-9af2-e252890435e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Sentiment'].describe()\n",
        "#We have a very balanced classes here."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ideMBt_rpmtt",
        "outputId": "6e50b8eb-3e09-443e-e917-91a370d84b13"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count         1800\n",
              "unique           2\n",
              "top       Positive\n",
              "freq           900\n",
              "Name: Sentiment, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first we define a list of arabic and english punctiations that we want to get rid of in our text\n",
        "punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ''' + string.punctuation\n",
        "# Arabic stop words with nltk\n",
        "stop_words = stopwords.words()\n",
        "\n",
        "arabic_diacritics = re.compile(\"\"\"\n",
        "                             ّ    | # Shadda\n",
        "                             َ    | # Fatha\n",
        "                             ً    | # Tanwin Fath\n",
        "                             ُ    | # Damma\n",
        "                             ٌ    | # Tanwin Damm\n",
        "                             ِ    | # Kasra\n",
        "                             ٍ    | # Tanwin Kasr\n",
        "                             ْ    | # Sukun\n",
        "                             ـ     # Tatwil/Kashida\n",
        "                         \"\"\", re.VERBOSE)\n",
        "def preprocess(text):\n",
        "    \n",
        "    '''\n",
        "    text is an arabic string input\n",
        "    \n",
        "    the preprocessed text is returned\n",
        "    '''\n",
        "    \n",
        "    #remove punctuations\n",
        "    translator = str.maketrans('', '', punctuations)\n",
        "    text = text.translate(translator)\n",
        "    \n",
        "    # remove Tashkeel\n",
        "    text = re.sub(arabic_diacritics, '', text)\n",
        "    \n",
        "    #remove longation\n",
        "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ؤ\", \"ء\", text)\n",
        "    text = re.sub(\"ئ\", \"ء\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    text = re.sub(\"گ\", \"ك\", text)\n",
        "\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "\n",
        "    return text\n",
        "  \n",
        "data['Feed'] = data['Feed'].apply(preprocess)\n",
        "print(data.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz96cflUqWYg",
        "outputId": "6ccee70d-d15d-41ec-e768-19cd67915946"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID                                               Feed Sentiment\n",
            "0   1  اربد جامعات اكثر عمان وفيها عمان ونص لعيبه الم...  Positive\n",
            "1   2   الحلو انكم بتحكوا علي اساس انو الاردن فساد سرقات  Negative\n",
            "2   3                            كله راءع بجد ربنا يكرمك  Positive\n",
            "3   4                                    لسانك قذر قمامه  Negative\n",
            "4   5  ​انا داشره وغير متزوجه ولدي علاقات مشبوه واحشش...  Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the data into target and feature\n",
        "feature = data.Feed\n",
        "target = data.Sentiment\n",
        "# splitting into train and tests\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(feature, target, test_size =.2, random_state=100)\n",
        "\n",
        "# make pipeline\n",
        "pipe = make_pipeline(TfidfVectorizer(),\n",
        "                    LogisticRegression())\n",
        "# make param grid\n",
        "param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# create and fit the model\n",
        "model = GridSearchCV(pipe, param_grid, cv=5)\n",
        "model.fit(X_train,Y_train)\n",
        "\n",
        "# make prediction and print accuracy\n",
        "prediction = model.predict(X_test)\n",
        "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
        "print(classification_report(Y_test, prediction))\n",
        "filename = '/content/LogisticRegression.sav'\n",
        "joblib.dump(model, filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r6IgwJqsuHD",
        "outputId": "0e5d5ac3-c8cc-49a0-fc7c-b5b6c75fffc0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 0.83\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.85      0.80      0.82       176\n",
            "    Positive       0.82      0.86      0.84       184\n",
            "\n",
            "    accuracy                           0.83       360\n",
            "   macro avg       0.83      0.83      0.83       360\n",
            "weighted avg       0.83      0.83      0.83       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RandomForestClassifier\n",
        "pipe = make_pipeline(TfidfVectorizer(),\n",
        "                    RandomForestClassifier())\n",
        "\n",
        "param_grid = {'randomforestclassifier__n_estimators':[10, 100, 1000],\n",
        "             'randomforestclassifier__max_features':['sqrt', 'log2']}\n",
        "\n",
        "rf_model = GridSearchCV(pipe, param_grid, cv=5)\n",
        "rf_model.fit(X_train,Y_train)\n",
        "\n",
        "prediction = rf_model.predict(X_test)\n",
        "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
        "filename = '/content/RandomForestClassifier.sav'\n",
        "joblib.dump(rf_model, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhMGJxXvuV0c",
        "outputId": "78507f83-2f11-4dad-b2de-caae43c2c9ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes Classifier (Multinomial)\n",
        "pipe = make_pipeline(TfidfVectorizer(),\n",
        "                    MultinomialNB())\n",
        "pipe.fit(X_train,Y_train)\n",
        "prediction = pipe.predict(X_test)\n",
        "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
        "print(classification_report(Y_test, prediction))\n",
        "filename = '/content/Multinomial.sav'\n",
        "joblib.dump(pipe, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a95jblJLuiT7",
        "outputId": "c599725c-53d2-4499-d0bd-80c4266d002a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 0.83\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.89      0.76      0.82       176\n",
            "    Positive       0.80      0.91      0.85       184\n",
            "\n",
            "    accuracy                           0.83       360\n",
            "   macro avg       0.84      0.83      0.83       360\n",
            "weighted avg       0.84      0.83      0.83       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Support Vector Machine\n",
        "pipe = make_pipeline(TfidfVectorizer(),\n",
        "                     SVC())\n",
        "param_grid = {'svc__kernel': ['rbf', 'linear', 'poly'],\n",
        "             'svc__gamma': [0.1, 1, 10, 100],\n",
        "             'svc__C': [0.1, 1, 10, 100]}\n",
        "\n",
        "svc_model = GridSearchCV(pipe, param_grid, cv=3)\n",
        "svc_model.fit(X_train, Y_train)\n",
        "\n",
        "prediction = svc_model.predict(X_test)\n",
        "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
        "print(classification_report(Y_test, prediction))\n",
        "filename = '/content/SVC.sav'\n",
        "joblib.dump(svc_model, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZzNy42qu3x-",
        "outputId": "9a82e007-7dc9-4fe1-fff4-d07c10188e81"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score is 0.85\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.83      0.87      0.85       176\n",
            "    Positive       0.87      0.83      0.85       184\n",
            "\n",
            "    accuracy                           0.85       360\n",
            "   macro avg       0.85      0.85      0.85       360\n",
            "weighted avg       0.85      0.85      0.85       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ktSjx2iCa2LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n3RdLdFtHbnK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}